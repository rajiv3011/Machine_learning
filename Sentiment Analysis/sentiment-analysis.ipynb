{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":10731136,"sourceType":"datasetVersion","datasetId":6653222},{"sourceId":257723,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":220261,"modelId":242025}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:55:32.421793Z","iopub.execute_input":"2025-02-14T00:55:32.422268Z","iopub.status.idle":"2025-02-14T00:55:32.441663Z","shell.execute_reply.started":"2025-02-14T00:55:32.422240Z","shell.execute_reply":"2025-02-14T00:55:32.440854Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n/kaggle/input/word2vec/pytorch/default/1/word2vec (1).model\n/kaggle/input/preprocessed-sentiment-data/preprocessed_sentiment_data.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:55:37.108581Z","iopub.execute_input":"2025-02-14T00:55:37.108895Z","iopub.status.idle":"2025-02-14T00:55:37.112356Z","shell.execute_reply.started":"2025-02-14T00:55:37.108866Z","shell.execute_reply":"2025-02-14T00:55:37.111531Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:08.302860Z","iopub.execute_input":"2025-02-12T13:01:08.303259Z","iopub.status.idle":"2025-02-12T13:01:09.888688Z","shell.execute_reply.started":"2025-02-12T13:01:08.303229Z","shell.execute_reply":"2025-02-12T13:01:09.887453Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:13.308900Z","iopub.execute_input":"2025-02-12T13:01:13.309455Z","iopub.status.idle":"2025-02-12T13:01:13.337196Z","shell.execute_reply.started":"2025-02-12T13:01:13.309412Z","shell.execute_reply":"2025-02-12T13:01:13.336191Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:16.473508Z","iopub.execute_input":"2025-02-12T13:01:16.473840Z","iopub.status.idle":"2025-02-12T13:01:16.512151Z","shell.execute_reply.started":"2025-02-12T13:01:16.473813Z","shell.execute_reply":"2025-02-12T13:01:16.510982Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   review     50000 non-null  object\n 1   sentiment  50000 non-null  object\ndtypes: object(2)\nmemory usage: 781.4+ KB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df['review'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:20.516212Z","iopub.execute_input":"2025-02-12T13:01:20.516541Z","iopub.status.idle":"2025-02-12T13:01:20.522990Z","shell.execute_reply.started":"2025-02-12T13:01:20.516517Z","shell.execute_reply":"2025-02-12T13:01:20.521952Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df['sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:23.512920Z","iopub.execute_input":"2025-02-12T13:01:23.513301Z","iopub.status.idle":"2025-02-12T13:01:23.523628Z","shell.execute_reply.started":"2025-02-12T13:01:23.513272Z","shell.execute_reply":"2025-02-12T13:01:23.522632Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    25000\nnegative    25000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:26.650708Z","iopub.execute_input":"2025-02-12T13:01:26.651046Z","iopub.status.idle":"2025-02-12T13:01:26.668026Z","shell.execute_reply.started":"2025-02-12T13:01:26.651018Z","shell.execute_reply":"2025-02-12T13:01:26.667162Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:49.647030Z","iopub.execute_input":"2025-02-12T13:01:49.647420Z","iopub.status.idle":"2025-02-12T13:01:49.829598Z","shell.execute_reply.started":"2025-02-12T13:01:49.647393Z","shell.execute_reply":"2025-02-12T13:01:49.828680Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"418"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:53.068294Z","iopub.execute_input":"2025-02-12T13:01:53.068617Z","iopub.status.idle":"2025-02-12T13:01:53.252729Z","shell.execute_reply.started":"2025-02-12T13:01:53.068593Z","shell.execute_reply":"2025-02-12T13:01:53.251768Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:01:56.427499Z","iopub.execute_input":"2025-02-12T13:01:56.427853Z","iopub.status.idle":"2025-02-12T13:01:56.612568Z","shell.execute_reply.started":"2025-02-12T13:01:56.427824Z","shell.execute_reply":"2025-02-12T13:01:56.611173Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Text Preprocessing","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('stopwords')\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T18:45:13.715777Z","iopub.execute_input":"2025-02-13T18:45:13.716044Z","iopub.status.idle":"2025-02-13T18:45:14.893924Z","shell.execute_reply.started":"2025-02-13T18:45:13.716023Z","shell.execute_reply":"2025-02-13T18:45:14.893116Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()  # Lowercasing\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n    text = re.sub(re.compile('<.*?>'), '', text)  # tags\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n    tokens = word_tokenize(text)  # Tokenization\n    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Stopword removal\n    return \" \".join(tokens)\n\ndf['cleaned_text'] = df['review'].apply(preprocess_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T20:12:55.658148Z","iopub.execute_input":"2025-02-11T20:12:55.658727Z","iopub.status.idle":"2025-02-11T20:35:34.832157Z","shell.execute_reply.started":"2025-02-11T20:12:55.658689Z","shell.execute_reply":"2025-02-11T20:35:34.830892Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T20:38:35.209841Z","iopub.execute_input":"2025-02-11T20:38:35.210275Z","iopub.status.idle":"2025-02-11T20:38:35.223469Z","shell.execute_reply.started":"2025-02-11T20:38:35.210226Z","shell.execute_reply":"2025-02-11T20:38:35.222324Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment  \\\n0      One of the other reviewers has mentioned that ...  positive   \n1      A wonderful little production. <br /><br />The...  positive   \n2      I thought this was a wonderful way to spend ti...  positive   \n3      Basically there's a family where a little boy ...  negative   \n4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n...                                                  ...       ...   \n49995  I thought this movie did a down right good job...  positive   \n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n49997  I am a Catholic taught in parochial elementary...  negative   \n49998  I'm going to have to disagree with the previou...  negative   \n49999  No one expects the Star Trek movies to be high...  negative   \n\n                                            cleaned_text  \n0      one reviewers mentioned watching oz episode yo...  \n1      wonderful little production filming technique ...  \n2      thought wonderful way spend time hot summer we...  \n3      basically theres family little boy jake thinks...  \n4      petter matteis love time money visually stunni...  \n...                                                  ...  \n49995  thought movie right good job wasnt creative or...  \n49996  bad plot bad dialogue bad acting idiotic direc...  \n49997  catholic taught parochial elementary schools n...  \n49998  im going disagree previous comment side maltin...  \n49999  one expects star trek movies high art fans exp...  \n\n[49582 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>one reviewers mentioned watching oz episode yo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>wonderful little production filming technique ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>thought wonderful way spend time hot summer we...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>basically theres family little boy jake thinks...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>petter matteis love time money visually stunni...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n      <td>thought movie right good job wasnt creative or...</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n      <td>catholic taught parochial elementary schools n...</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n      <td>im going disagree previous comment side maltin...</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n      <td>one expects star trek movies high art fans exp...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef lemmass(text):\n    doc = nlp(text)\n    lemmas = [token.lemma_ for token in doc]\n    return ' '.join(lemmas)\n\ndf['cleaned_text'] = df['cleaned_text'].apply(lemmass)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T20:38:40.556065Z","iopub.execute_input":"2025-02-11T20:38:40.556533Z","iopub.status.idle":"2025-02-11T21:00:01.960807Z","shell.execute_reply.started":"2025-02-11T20:38:40.556495Z","shell.execute_reply":"2025-02-11T21:00:01.959517Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"df=df[['cleaned_text','sentiment']]\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T21:00:45.233213Z","iopub.execute_input":"2025-02-11T21:00:45.233924Z","iopub.status.idle":"2025-02-11T21:00:45.255407Z","shell.execute_reply.started":"2025-02-11T21:00:45.233883Z","shell.execute_reply":"2025-02-11T21:00:45.253941Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                            cleaned_text sentiment\n0      one reviewer mention watch oz episode you ll h...  positive\n1      wonderful little production filming technique ...  positive\n2      think wonderful way spend time hot summer week...  positive\n3      basically there s family little boy jake think...  negative\n4      petter matteis love time money visually stunni...  positive\n...                                                  ...       ...\n49995  think movie right good job be not creative ori...  positive\n49996  bad plot bad dialogue bad act idiotic direct a...  negative\n49997  catholic teach parochial elementary school nun...  negative\n49998  I m go disagree previous comment side maltin o...  negative\n49999  one expect star trek movie high art fan expect...  negative\n\n[49582 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewer mention watch oz episode you ll h...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>think wonderful way spend time hot summer week...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there s family little boy jake think...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love time money visually stunni...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>think movie right good job be not creative ori...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>bad plot bad dialogue bad act idiotic direct a...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>catholic teach parochial elementary school nun...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I m go disagree previous comment side maltin o...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>one expect star trek movie high art fan expect...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>49582 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# Save & Load Preprocessed Data","metadata":{}},{"cell_type":"code","source":"df.to_csv(\"preprocessed_sentiment_data.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/preprocessed-sentiment-data/preprocessed_sentiment_data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:55:46.609322Z","iopub.execute_input":"2025-02-14T00:55:46.609639Z","iopub.status.idle":"2025-02-14T00:55:47.409355Z","shell.execute_reply.started":"2025-02-14T00:55:46.609611Z","shell.execute_reply":"2025-02-14T00:55:47.408693Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Train and Test","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:,0:1]\ny = df['sentiment']\n\nprint(X)\nprint(y)\n\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\nprint(y)\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:55:52.775746Z","iopub.execute_input":"2025-02-14T00:55:52.776025Z","iopub.status.idle":"2025-02-14T00:55:53.316074Z","shell.execute_reply.started":"2025-02-14T00:55:52.776003Z","shell.execute_reply":"2025-02-14T00:55:53.315328Z"}},"outputs":[{"name":"stdout","text":"                                            cleaned_text\n0      one reviewer mention watch oz episode you ll h...\n1      wonderful little production filming technique ...\n2      think wonderful way spend time hot summer week...\n3      basically there s family little boy jake think...\n4      petter matteis love time money visually stunni...\n...                                                  ...\n49577  think movie right good job be not creative ori...\n49578  bad plot bad dialogue bad act idiotic direct a...\n49579  catholic teach parochial elementary school nun...\n49580  I m go disagree previous comment side maltin o...\n49581  one expect star trek movie high art fan expect...\n\n[49582 rows x 1 columns]\n0        positive\n1        positive\n2        positive\n3        negative\n4        positive\n           ...   \n49577    positive\n49578    negative\n49579    negative\n49580    negative\n49581    negative\nName: sentiment, Length: 49582, dtype: object\n[1 1 1 ... 0 0 0]\n(39665, 1) (9917, 1) (39665,) (9917,)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Convert Text to Vectors","metadata":{}},{"cell_type":"markdown","source":"### 1. Bag of Words (BOW)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=10000)\nX_train_bow1 = cv.fit_transform(X_train['cleaned_text']).toarray()\nX_test_bow1 = cv.transform(X_test['cleaned_text']).toarray()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:49:47.637178Z","iopub.execute_input":"2025-02-13T07:49:47.637509Z","iopub.status.idle":"2025-02-13T07:49:55.033004Z","shell.execute_reply.started":"2025-02-13T07:49:47.637482Z","shell.execute_reply":"2025-02-13T07:49:55.032065Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"X_train_bow1.shape,X_test_bow1.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:49:58.569591Z","iopub.execute_input":"2025-02-13T07:49:58.569906Z","iopub.status.idle":"2025-02-13T07:49:58.576214Z","shell.execute_reply.started":"2025-02-13T07:49:58.569882Z","shell.execute_reply":"2025-02-13T07:49:58.575291Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"((39665, 10000), (9917, 10000))"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"### 2. TfIdf","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(max_features=10000)\nX_train_tfidf1 = tfidf.fit_transform(X_train['cleaned_text'])\nX_test_tfidf1 = tfidf.transform(X_test['cleaned_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:55:59.055233Z","iopub.execute_input":"2025-02-14T00:55:59.055721Z","iopub.status.idle":"2025-02-14T00:56:03.890176Z","shell.execute_reply.started":"2025-02-14T00:55:59.055690Z","shell.execute_reply":"2025-02-14T00:56:03.889238Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"X_train_tfidf1.shape,X_test_tfidf1.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:56:05.850018Z","iopub.execute_input":"2025-02-14T00:56:05.850336Z","iopub.status.idle":"2025-02-14T00:56:05.856203Z","shell.execute_reply.started":"2025-02-14T00:56:05.850307Z","shell.execute_reply":"2025-02-14T00:56:05.855354Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"((39665, 10000), (9917, 10000))"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### 3. Word2vec","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom gensim.models import Word2Vec\nfrom nltk.tokenize import word_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:30:22.704711Z","iopub.execute_input":"2025-02-13T19:30:22.705199Z","iopub.status.idle":"2025-02-13T19:30:31.873079Z","shell.execute_reply.started":"2025-02-13T19:30:22.705171Z","shell.execute_reply":"2025-02-13T19:30:31.872122Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in X_train['cleaned_text']]\n\nword2vec_model = Word2Vec(sentences=tokenized_corpus, vector_size=300, window=5, min_count=1, workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:30:36.451804Z","iopub.execute_input":"2025-02-13T19:30:36.452461Z","iopub.status.idle":"2025-02-13T19:31:28.246274Z","shell.execute_reply.started":"2025-02-13T19:30:36.452422Z","shell.execute_reply":"2025-02-13T19:31:28.245566Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(word2vec_model.wv['watch'])  # Example word embeddin\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:31:43.286792Z","iopub.execute_input":"2025-02-13T19:31:43.287096Z","iopub.status.idle":"2025-02-13T19:31:43.302046Z","shell.execute_reply.started":"2025-02-13T19:31:43.287074Z","shell.execute_reply":"2025-02-13T19:31:43.301288Z"}},"outputs":[{"name":"stdout","text":"[ 0.02491953 -1.0913501   0.14735903 -0.6497404   1.3276836   0.5583584\n  0.9968599   0.70203054  0.52654666 -0.22924031  0.00974168  0.34475282\n -1.7714472  -0.41322938 -1.0833504  -0.1131838   1.3735849   0.398398\n  1.6907634  -0.9985803   0.2885862   0.06600291  0.49371925  0.01361038\n -0.26424694  0.72129405 -0.74179727 -0.35931048  0.7354718   0.4325307\n  0.7961574  -0.22549355  0.96308523  0.15833628 -0.60517365 -0.6502583\n -2.5667667  -1.4583397   0.5311674   0.10063814  0.0450785  -0.2851342\n  1.1798848  -1.179137   -1.0731796  -0.19313093 -0.08611448  0.70088345\n -0.5242068   0.87944776 -0.03869414  0.8254978   0.57637036  0.36325517\n  0.8194674   0.79182553  0.20090923 -0.09786388  0.78275347 -0.00733812\n -0.37132046 -0.80092144  0.11803232  1.6788431  -0.81999207  0.2745788\n  0.79905534 -0.13191465 -1.7405558  -0.13199843 -0.39005795  0.63273585\n  0.39711633 -0.66656566  0.70931846  0.8683811   0.49707744  0.15708178\n -0.8089754  -0.3290382  -1.0001711   1.2454933  -1.2031784   1.6153077\n  0.45845723 -0.7884485   0.8902488  -0.81596047  0.35092446 -0.13417408\n -0.6485227  -0.75092596  0.5931732  -0.984455    1.0086979   0.30061123\n  0.00845932  0.51723975 -0.9740953   0.33507502  0.72807825 -0.23011315\n -0.8039921   1.4132524   0.54322076 -0.87997705 -0.88055736 -0.48227218\n -0.6153068  -1.5055116   0.05428011 -1.190777   -0.13978145  1.2815688\n  0.14507478  2.0737622   0.47426987  0.7933021   0.6774569  -0.76523334\n  0.00943754  1.1731097  -0.19250691 -0.77784604  0.7835782  -0.90110004\n -0.13387449  1.0083771   1.4402184   1.8132787   1.0119513   0.8968744\n  1.2263935  -1.2227305   0.38601723  0.71907     0.79859614 -0.44931507\n -1.8678439  -1.4013815  -0.01035048 -0.84986097 -1.4251966   0.39731815\n -0.3057928  -0.75663555 -0.5362136   1.5219697   0.08484433  0.8759621\n -0.207954   -0.7837915   0.02603851  0.7572751   0.2520023   1.2060643\n  0.60551083 -1.6398727   0.16261463  1.0077773  -0.3725859   1.2125279\n  0.36824474  1.4214073  -0.531751    0.5606976   0.01767411  0.52360123\n  0.54153     0.5573606  -0.01405446 -0.06877116  1.6530299   0.8627517\n -0.5136036  -0.04589988  1.417778   -1.8547103  -1.160593    0.8405332\n  0.7270955   0.25475612 -0.01994847  0.4569829   0.36240608  0.73191917\n  0.688944    0.29056013  1.7203723  -0.80685073  0.47685546  1.9570245\n -0.11062173  1.9181932   1.8751769  -0.42578253  0.60179186 -0.9934079\n  0.2765366   0.8947514  -0.6161885  -0.7503122   0.5039248   0.80028516\n  0.38906986 -0.14158285  1.094609   -0.3627303   1.3366871  -2.2564528\n  0.22524852  0.16897179  1.7104168  -0.8196422   0.5519292   1.1728781\n  0.6649289  -0.8921741   1.3079945  -1.0449749   0.31432047  2.6267383\n  0.8682249  -0.41742608  0.32566988  1.1734123  -0.80872405  0.23992562\n -0.3479907  -1.0582715   0.3189967   0.86006474 -1.3427063  -0.5141238\n -1.3007957   0.01149896 -1.1467651  -0.44495586 -0.18240762  0.31010327\n  0.06952497  0.00438504  0.31154007 -1.2512178   0.4413135  -0.53431845\n  0.74702704 -0.86819583  0.5543683  -0.13850683  0.76865864 -0.41456532\n -0.6978112  -1.0756142  -0.9968237  -1.1579782  -1.257804   -1.9294457\n  0.3508294  -0.44169268  0.24015652  0.26052472  0.5100398   0.69624364\n -0.66965     1.4421235  -0.77758807 -0.18164262  0.07975869  0.17454092\n  0.7831603   0.82059133  1.3531212   0.5138803   0.20619339 -0.42225626\n  0.6452979  -0.5190191  -0.04600806 -0.6926309   0.02387361 -0.28734776\n -0.4756379   0.53021765  0.6896747   0.04094024  0.513387    0.6604351\n -0.8251686   0.26028553  0.31597728  0.63219595  0.48160934  1.6166975\n  1.2081745   0.45881698  0.7891706   0.6658722   0.08705401  0.02156893]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"word2vec_model.save(\"word2vec.model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:18:19.931736Z","iopub.execute_input":"2025-02-13T19:18:19.932047Z","iopub.status.idle":"2025-02-13T19:18:20.282808Z","shell.execute_reply.started":"2025-02-13T19:18:19.932023Z","shell.execute_reply":"2025-02-13T19:18:20.281853Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"word2vec_model = Word2Vec.load(\"/kaggle/input/word2vec/pytorch/default/1/word2vec(1).model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef sentence_to_vector(sentence, model, vector_size=300):\n    words = word_tokenize(sentence.lower())  \n    word_vectors = [model.wv[word] for word in words if word in model.wv]\n    \n    if len(word_vectors) == 0:\n        return np.zeros(vector_size) \n\n\n    return np.mean(word_vectors, axis=0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T18:48:59.641102Z","iopub.execute_input":"2025-02-13T18:48:59.641420Z","iopub.status.idle":"2025-02-13T18:48:59.645947Z","shell.execute_reply.started":"2025-02-13T18:48:59.641395Z","shell.execute_reply":"2025-02-13T18:48:59.645132Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm  \n\nX_train_word2vec = np.array([sentence_to_vector(text, word2vec_model) for text in tqdm(X_train[\"cleaned_text\"])])\nX_test_word2vec = np.array([sentence_to_vector(text, word2vec_model) for text in tqdm(X_test[\"cleaned_text\"])])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T18:49:03.240812Z","iopub.execute_input":"2025-02-13T18:49:03.241079Z","iopub.status.idle":"2025-02-13T18:49:43.436308Z","shell.execute_reply.started":"2025-02-13T18:49:03.241058Z","shell.execute_reply":"2025-02-13T18:49:43.435492Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 39665/39665 [00:32<00:00, 1233.94it/s]\n100%|██████████| 9917/9917 [00:07<00:00, 1242.75it/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"X_train_word2vec.shape,X_test_word2vec.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T18:49:51.014654Z","iopub.execute_input":"2025-02-13T18:49:51.014964Z","iopub.status.idle":"2025-02-13T18:49:51.019799Z","shell.execute_reply.started":"2025-02-13T18:49:51.014936Z","shell.execute_reply":"2025-02-13T18:49:51.019010Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((39665, 300), (9917, 300))"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"### 1. Naive bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:21:33.303209Z","iopub.execute_input":"2025-02-13T08:21:33.303546Z","iopub.status.idle":"2025-02-13T08:21:33.314257Z","shell.execute_reply.started":"2025-02-13T08:21:33.303518Z","shell.execute_reply":"2025-02-13T08:21:33.313548Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"nb_model = MultinomialNB()\nnb_model.fit(X_train_bow1, y_train)\n\ny_pred = nb_model.predict(X_test_bow1)\n\n# Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T21:25:48.794049Z","iopub.execute_input":"2025-02-11T21:25:48.794514Z","iopub.status.idle":"2025-02-11T21:26:06.303571Z","shell.execute_reply.started":"2025-02-11T21:25:48.794472Z","shell.execute_reply":"2025-02-11T21:26:06.301902Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8437027326812544\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.84      0.85      0.85      5033\n           1       0.85      0.84      0.84      4884\n\n    accuracy                           0.84      9917\n   macro avg       0.84      0.84      0.84      9917\nweighted avg       0.84      0.84      0.84      9917\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"nb_model = MultinomialNB()\nnb_model.fit(X_train_tfidf1, y_train)\n\ny_pred = nb_model.predict(X_test_tfidf1)\n\n# Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:56:45.569501Z","iopub.execute_input":"2025-02-12T13:56:45.569871Z","iopub.status.idle":"2025-02-12T13:56:46.954223Z","shell.execute_reply.started":"2025-02-12T13:56:45.569843Z","shell.execute_reply":"2025-02-12T13:56:46.953120Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8531814056670364\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.86      0.85      0.85      5033\n           1       0.85      0.86      0.85      4884\n\n    accuracy                           0.85      9917\n   macro avg       0.85      0.85      0.85      9917\nweighted avg       0.85      0.85      0.85      9917\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"gnb_model = GaussianNB()\ngnb_model.fit(X_train_bow1, y_train)\n\ny_pred = gnb_model.predict(X_test_bow1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T11:15:58.967393Z","iopub.execute_input":"2025-02-12T11:15:58.967758Z","iopub.status.idle":"2025-02-12T11:16:08.423708Z","shell.execute_reply.started":"2025-02-12T11:15:58.967730Z","shell.execute_reply":"2025-02-12T11:16:08.422540Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7137239084400524\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.67      0.87      0.75      5033\n           1       0.80      0.56      0.66      4884\n\n    accuracy                           0.71      9917\n   macro avg       0.73      0.71      0.71      9917\nweighted avg       0.73      0.71      0.71      9917\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"X_train_dense = X_train_tfidf1\nX_test_dense = X_test_tfidf1.toarray()\ngnb_model = GaussianNB()\ngnb_model.fit(X_train_dense, y_train)\n\ny_pred = gnb_model.predict(X_test_dense)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:54:46.511554Z","iopub.execute_input":"2025-02-12T16:54:46.511975Z","iopub.status.idle":"2025-02-12T16:54:55.018464Z","shell.execute_reply.started":"2025-02-12T16:54:46.511944Z","shell.execute_reply":"2025-02-12T16:54:55.017434Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7770495109408088\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.81      0.79      5033\n           1       0.79      0.74      0.77      4884\n\n    accuracy                           0.78      9917\n   macro avg       0.78      0.78      0.78      9917\nweighted avg       0.78      0.78      0.78      9917\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"gnb_model = GaussianNB()\ngnb_model.fit(X_train_word2vec, y_train)\n\ny_pred = gnb_model.predict(X_test_word2vec)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:24:17.450411Z","iopub.execute_input":"2025-02-13T08:24:17.450723Z","iopub.status.idle":"2025-02-13T08:24:17.614019Z","shell.execute_reply.started":"2025-02-13T08:24:17.450697Z","shell.execute_reply":"2025-02-13T08:24:17.613253Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7544620348895835\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.76      0.76      5033\n           1       0.75      0.75      0.75      4884\n\n    accuracy                           0.75      9917\n   macro avg       0.75      0.75      0.75      9917\nweighted avg       0.75      0.75      0.75      9917\n\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"### 2. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:24:22.876979Z","iopub.execute_input":"2025-02-13T08:24:22.877292Z","iopub.status.idle":"2025-02-13T08:24:23.074865Z","shell.execute_reply.started":"2025-02-13T08:24:22.877270Z","shell.execute_reply":"2025-02-13T08:24:23.073967Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"rf_model = RandomForestClassifier()\nrf_model.fit(X_train_bow1, y_train)\n\ny_pred = rf_model.predict(X_test_bow1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T11:19:02.311846Z","iopub.execute_input":"2025-02-12T11:19:02.312285Z","iopub.status.idle":"2025-02-12T11:21:34.042013Z","shell.execute_reply.started":"2025-02-12T11:19:02.312249Z","shell.execute_reply":"2025-02-12T11:21:34.040796Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8432993848946254\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85      5033\n           1       0.84      0.84      0.84      4884\n\n    accuracy                           0.84      9917\n   macro avg       0.84      0.84      0.84      9917\nweighted avg       0.84      0.84      0.84      9917\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"rf_model = RandomForestClassifier()\nrf_model.fit(X_train_tfidf1, y_train)\n\ny_pred = rf_model.predict(X_test_tfidf1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:01:00.803991Z","iopub.execute_input":"2025-02-12T14:01:00.804431Z","iopub.status.idle":"2025-02-12T14:03:57.879167Z","shell.execute_reply.started":"2025-02-12T14:01:00.804397Z","shell.execute_reply":"2025-02-12T14:03:57.877979Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8428960371079963\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.85      0.84      0.84      5033\n           1       0.84      0.84      0.84      4884\n\n    accuracy                           0.84      9917\n   macro avg       0.84      0.84      0.84      9917\nweighted avg       0.84      0.84      0.84      9917\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"rf_model = RandomForestClassifier()\nrf_model.fit(X_train_word2vec, y_train)\n\ny_pred = rf_model.predict(X_test_word2vec)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:24:54.100315Z","iopub.execute_input":"2025-02-13T08:24:54.100691Z","iopub.status.idle":"2025-02-13T08:26:10.787555Z","shell.execute_reply.started":"2025-02-13T08:24:54.100667Z","shell.execute_reply":"2025-02-13T08:26:10.786785Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8255520822829485\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.85      0.80      0.82      5033\n           1       0.81      0.85      0.83      4884\n\n    accuracy                           0.83      9917\n   macro avg       0.83      0.83      0.83      9917\nweighted avg       0.83      0.83      0.83      9917\n\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"### 3. XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:56:30.870852Z","iopub.execute_input":"2025-02-14T00:56:30.871141Z","iopub.status.idle":"2025-02-14T00:56:31.148310Z","shell.execute_reply.started":"2025-02-14T00:56:30.871118Z","shell.execute_reply":"2025-02-14T00:56:31.147422Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier()\nxgb_model.fit(X_train_bow1, y_train)\n\n# Predictions\ny_pred = xgb_model.predict(X_test_bow1)\n\n# Evaluate\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T11:41:37.795656Z","iopub.execute_input":"2025-02-12T11:41:37.796116Z","iopub.status.idle":"2025-02-12T11:42:58.586420Z","shell.execute_reply.started":"2025-02-12T11:41:37.796072Z","shell.execute_reply":"2025-02-12T11:42:58.584895Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8511646667338914\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.82      0.85      5033\n           1       0.83      0.88      0.85      4884\n\n    accuracy                           0.85      9917\n   macro avg       0.85      0.85      0.85      9917\nweighted avg       0.85      0.85      0.85      9917\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier()\nxgb_model.fit(X_train_tfidf1, y_train)\n\ny_pred = xgb_model.predict(X_test_tfidf1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:56:35.816953Z","iopub.execute_input":"2025-02-14T00:56:35.817275Z","iopub.status.idle":"2025-02-14T00:57:32.554368Z","shell.execute_reply.started":"2025-02-14T00:56:35.817247Z","shell.execute_reply":"2025-02-14T00:57:32.553538Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8541897751336089\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.83      0.85      5033\n           1       0.83      0.88      0.86      4884\n\n    accuracy                           0.85      9917\n   macro avg       0.85      0.85      0.85      9917\nweighted avg       0.86      0.85      0.85      9917\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier()\nxgb_model.fit(X_train_word2vec, y_train)\n\n# Predictions\ny_pred = xgb_model.predict(X_test_word2vec)\n\n# Evaluate\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:27:15.079193Z","iopub.execute_input":"2025-02-13T08:27:15.079608Z","iopub.status.idle":"2025-02-13T08:27:23.961023Z","shell.execute_reply.started":"2025-02-13T08:27:15.079575Z","shell.execute_reply":"2025-02-13T08:27:23.960094Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8436018957345972\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.86      0.83      0.84      5033\n           1       0.83      0.86      0.84      4884\n\n    accuracy                           0.84      9917\n   macro avg       0.84      0.84      0.84      9917\nweighted avg       0.84      0.84      0.84      9917\n\n","output_type":"stream"}],"execution_count":85},{"cell_type":"markdown","source":"### 4. CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:28:36.380811Z","iopub.execute_input":"2025-02-13T08:28:36.381112Z","iopub.status.idle":"2025-02-13T08:28:36.616284Z","shell.execute_reply.started":"2025-02-13T08:28:36.381091Z","shell.execute_reply":"2025-02-13T08:28:36.615636Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"cat_model = CatBoostClassifier(verbose=False)\ncat_model.fit(X_train_bow1, y_train)\n\ny_pred = cat_model.predict(X_test_bow1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:03:35.105300Z","iopub.execute_input":"2025-02-12T13:03:35.105688Z","iopub.status.idle":"2025-02-12T13:10:06.397099Z","shell.execute_reply.started":"2025-02-12T13:03:35.105661Z","shell.execute_reply":"2025-02-12T13:10:06.395957Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8710295452253706\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.85      0.87      5033\n           1       0.85      0.90      0.87      4884\n\n    accuracy                           0.87      9917\n   macro avg       0.87      0.87      0.87      9917\nweighted avg       0.87      0.87      0.87      9917\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"cat_model = CatBoostClassifier(verbose=False)\ncat_model.fit(X_train_tfidf1, y_train)\n\ny_pred = cat_model.predict(X_test_tfidf1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:08:43.517420Z","iopub.execute_input":"2025-02-12T17:08:43.517870Z","iopub.status.idle":"2025-02-12T17:22:22.769073Z","shell.execute_reply.started":"2025-02-12T17:08:43.517838Z","shell.execute_reply":"2025-02-12T17:22:22.767975Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8662902087324795\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.84      0.86      5033\n           1       0.85      0.89      0.87      4884\n\n    accuracy                           0.87      9917\n   macro avg       0.87      0.87      0.87      9917\nweighted avg       0.87      0.87      0.87      9917\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"cat_model = CatBoostClassifier(verbose=False)\ncat_model.fit(X_train_word2vec, y_train)\n\ny_pred = cat_model.predict(X_test_word2vec)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:29:12.302586Z","iopub.execute_input":"2025-02-13T08:29:12.302880Z","iopub.status.idle":"2025-02-13T08:30:07.567126Z","shell.execute_reply.started":"2025-02-13T08:29:12.302858Z","shell.execute_reply":"2025-02-13T08:30:07.566238Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8574165574266411\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86      5033\n           1       0.84      0.87      0.86      4884\n\n    accuracy                           0.86      9917\n   macro avg       0.86      0.86      0.86      9917\nweighted avg       0.86      0.86      0.86      9917\n\n","output_type":"stream"}],"execution_count":87},{"cell_type":"markdown","source":"### 5. Lightgbm","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:36:07.261271Z","iopub.execute_input":"2025-02-13T08:36:07.261582Z","iopub.status.idle":"2025-02-13T08:36:10.887583Z","shell.execute_reply.started":"2025-02-13T08:36:07.261560Z","shell.execute_reply":"2025-02-13T08:36:10.886872Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"lgb_model = LGBMClassifier(n_jobs=-1,verbose=0)\nlgb_model.fit(X_train_bow1, y_train)\n\ny_pred = lgb_model.predict(X_test_bow1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:29:26.368278Z","iopub.execute_input":"2025-02-12T13:29:26.368634Z","iopub.status.idle":"2025-02-12T13:29:43.987295Z","shell.execute_reply.started":"2025-02-12T13:29:26.368608Z","shell.execute_reply":"2025-02-12T13:29:43.986213Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8561056771200968\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.83      0.85      5033\n           1       0.84      0.88      0.86      4884\n\n    accuracy                           0.86      9917\n   macro avg       0.86      0.86      0.86      9917\nweighted avg       0.86      0.86      0.86      9917\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"lgb_model = LGBMClassifier(n_jobs=-1,verbose=0)\nlgb_model.fit(X_train_tfidf1, y_train)\n\ny_pred = lgb_model.predict(X_test_tfidf1)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:49:10.895180Z","iopub.execute_input":"2025-02-12T17:49:10.895852Z","iopub.status.idle":"2025-02-12T17:49:50.025464Z","shell.execute_reply.started":"2025-02-12T17:49:10.895819Z","shell.execute_reply":"2025-02-12T17:49:50.024446Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8566098618533831\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.87      0.84      0.86      5033\n           1       0.84      0.88      0.86      4884\n\n    accuracy                           0.86      9917\n   macro avg       0.86      0.86      0.86      9917\nweighted avg       0.86      0.86      0.86      9917\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"lgb_model = LGBMClassifier(n_jobs=-1,verbose=0)\nlgb_model.fit(X_train_word2vec, y_train)\n\ny_pred = lgb_model.predict(X_test_word2vec)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:36:34.143838Z","iopub.execute_input":"2025-02-13T08:36:34.144842Z","iopub.status.idle":"2025-02-13T08:36:40.252914Z","shell.execute_reply.started":"2025-02-13T08:36:34.144799Z","shell.execute_reply":"2025-02-13T08:36:40.252138Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.845517797721085\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.86      0.83      0.84      5033\n           1       0.83      0.86      0.85      4884\n\n    accuracy                           0.85      9917\n   macro avg       0.85      0.85      0.85      9917\nweighted avg       0.85      0.85      0.85      9917\n\n","output_type":"stream"}],"execution_count":90},{"cell_type":"markdown","source":"### 6. ANN","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nimport torchinfo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:32:00.388557Z","iopub.execute_input":"2025-02-13T19:32:00.388879Z","iopub.status.idle":"2025-02-13T19:32:04.786276Z","shell.execute_reply.started":"2025-02-13T19:32:00.388854Z","shell.execute_reply":"2025-02-13T19:32:04.785566Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:20:41.647377Z","iopub.execute_input":"2025-02-13T07:20:41.647864Z","iopub.status.idle":"2025-02-13T07:20:41.720781Z","shell.execute_reply.started":"2025-02-13T07:20:41.647828Z","shell.execute_reply":"2025-02-13T07:20:41.719889Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"X_train_tensor_bow = torch.tensor(X_train_bow1, dtype=torch.float32).to(device)\nY_train_tensor_bow = torch.tensor(y_train, dtype=torch.float32).to(device) \n\ntrain_dataset = TensorDataset(X_train_tensor_bow, Y_train_tensor_bow)\n\ntrain_dataloader_bow = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nfor batch in train_dataloader_bow:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(train_dataloader))\n\nX_test_tensor_bow = torch.tensor(X_test_bow1, dtype=torch.float32).to(device) \nY_test_tensor_bow = torch.tensor(y_test, dtype=torch.float32).to(device)  \n\ntest_dataset = TensorDataset(X_test_tensor_bow, Y_test_tensor_bow)\n\ntest_dataloader_bow = DataLoader(test_dataset, batch_size=32, shuffle=True)\n\nfor batch in test_dataloader_bow:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(test_dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:00:27.306674Z","iopub.execute_input":"2025-02-13T08:00:27.307003Z","iopub.status.idle":"2025-02-13T08:00:28.879798Z","shell.execute_reply.started":"2025-02-13T08:00:27.306976Z","shell.execute_reply":"2025-02-13T08:00:28.879118Z"}},"outputs":[{"name":"stdout","text":"X_batch shape: torch.Size([32, 10000])\nY_batch shape: torch.Size([32])\n1240\nX_batch shape: torch.Size([32, 10000])\nY_batch shape: torch.Size([32])\n310\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"X_train_dense = X_train_tfidf1.toarray()  \nX_test_dense = X_test_tfidf1.toarray()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:20:05.975463Z","iopub.execute_input":"2025-02-13T07:20:05.975769Z","iopub.status.idle":"2025-02-13T07:20:11.252430Z","shell.execute_reply.started":"2025-02-13T07:20:05.975745Z","shell.execute_reply":"2025-02-13T07:20:11.251491Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"X_train_tensor_tfidf = torch.tensor(X_train_dense, dtype=torch.float32).to(device) \nY_train_tensor_tfidf = torch.tensor(y_train, dtype=torch.float32).to(device)\n\ntrain_dataset = TensorDataset(X_train_tensor_tfidf, Y_train_tensor_tfidf)\n\ntrain_dataloader_tfidf = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nfor batch in train_dataloader_tfidf:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(train_dataloader_tfidf))\n\nX_test_tensor_tfidf = torch.tensor(X_test_dense, dtype=torch.float32).to(device)\nY_test_tensor_tfidf = torch.tensor(y_test, dtype=torch.float32).to(device) \n\ntest_dataset = TensorDataset(X_test_tensor_tfidf, Y_test_tensor_tfidf)\n\ntest_dataloader_tfidf = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nfor batch in test_dataloader_tfidf:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(test_dataloader_tfidf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:15:09.394328Z","iopub.execute_input":"2025-02-13T08:15:09.394699Z","iopub.status.idle":"2025-02-13T08:15:10.918777Z","shell.execute_reply.started":"2025-02-13T08:15:09.394673Z","shell.execute_reply":"2025-02-13T08:15:10.917879Z"}},"outputs":[{"name":"stdout","text":"X_batch shape: torch.Size([32, 10000])\nY_batch shape: torch.Size([32])\n1240\nX_batch shape: torch.Size([32, 10000])\nY_batch shape: torch.Size([32])\n310\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"X_train_tensor_word2vec = torch.tensor(X_train_word2vec, dtype=torch.float32).to(device) \nY_train_tensor_word2vec = torch.tensor(y_train, dtype=torch.float32).to(device)\n\ntrain_dataset = TensorDataset(X_train_tensor_word2vec, Y_train_tensor_tfidf)\n\ntrain_dataloader_word2vec = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nfor batch in train_dataloader_word2vec:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(train_dataloader_word2vec))\n\nX_test_tensor_word2vec = torch.tensor(X_test_word2vec, dtype=torch.float32).to(device)\nY_test_tensor_word2vec = torch.tensor(y_test, dtype=torch.float32).to(device) \n\ntest_dataset = TensorDataset(X_test_tensor_word2vec, Y_test_tensor_tfidf)\n\ntest_dataloader_word2vec = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nfor batch in test_dataloader_word2vec:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(test_dataloader_word2vec))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:40:12.820872Z","iopub.execute_input":"2025-02-13T08:40:12.821203Z","iopub.status.idle":"2025-02-13T08:40:12.860822Z","shell.execute_reply.started":"2025-02-13T08:40:12.821179Z","shell.execute_reply":"2025-02-13T08:40:12.859921Z"}},"outputs":[{"name":"stdout","text":"X_batch shape: torch.Size([32, 300])\nY_batch shape: torch.Size([32])\n1240\nX_batch shape: torch.Size([32, 300])\nY_batch shape: torch.Size([32])\n310\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"class ANN(nn.Module):\n    def __init__(self):\n        super(ANN, self).__init__()\n        \n        self.seq=nn.Sequential(\n            nn.Linear(in_features=10000,out_features=2000),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=2000,out_features=1),\n        )\n\n    def forward(self,x):\n        return self.seq(x)\n  \nmymodel=ANN().to(device)\n\nprint(\"Summary of the architecture (batch_size=32):\")\ntorchinfo.summary(mymodel, input_size=(32,10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:15:15.877768Z","iopub.execute_input":"2025-02-13T08:15:15.878085Z","iopub.status.idle":"2025-02-13T08:15:16.078492Z","shell.execute_reply.started":"2025-02-13T08:15:15.878060Z","shell.execute_reply":"2025-02-13T08:15:16.077789Z"}},"outputs":[{"name":"stdout","text":"Summary of the architecture (batch_size=32):\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nANN                                      [32, 1]                   --\n├─Sequential: 1-1                        [32, 1]                   --\n│    └─Linear: 2-1                       [32, 2000]                20,002,000\n│    └─ReLU: 2-2                         [32, 2000]                --\n│    └─Dropout: 2-3                      [32, 2000]                --\n│    └─Linear: 2-4                       [32, 1]                   2,001\n==========================================================================================\nTotal params: 20,004,001\nTrainable params: 20,004,001\nNon-trainable params: 0\nTotal mult-adds (M): 640.13\n==========================================================================================\nInput size (MB): 1.28\nForward/backward pass size (MB): 0.51\nParams size (MB): 80.02\nEstimated Total Size (MB): 81.81\n=========================================================================================="},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\noptimizer=torch.optim.Adam(params=mymodel.parameters(),lr=0.01, weight_decay=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:15:20.709529Z","iopub.execute_input":"2025-02-13T08:15:20.709824Z","iopub.status.idle":"2025-02-13T08:15:20.714255Z","shell.execute_reply.started":"2025-02-13T08:15:20.709792Z","shell.execute_reply":"2025-02-13T08:15:20.713437Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class ANN(nn.Module):\n    def __init__(self):\n        super(ANN, self).__init__()\n        \n        self.seq=nn.Sequential(\n            nn.Linear(in_features=300,out_features=200),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=200,out_features=100),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=100,out_features=10),\n            nn.ReLU(),\n            nn.Linear(in_features=10,out_features=1)\n        )\n\n    def forward(self,x):\n        return self.seq(x)\n  \nmymodel=ANN().to(device)\n\nprint(\"Summary of the architecture (batch_size=32):\")\ntorchinfo.summary(mymodel, input_size=(32,300))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:46:56.954522Z","iopub.execute_input":"2025-02-13T08:46:56.954836Z","iopub.status.idle":"2025-02-13T08:46:56.968396Z","shell.execute_reply.started":"2025-02-13T08:46:56.954790Z","shell.execute_reply":"2025-02-13T08:46:56.967662Z"}},"outputs":[{"name":"stdout","text":"Summary of the architecture (batch_size=32):\n","output_type":"stream"},{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nANN                                      [32, 1]                   --\n├─Sequential: 1-1                        [32, 1]                   --\n│    └─Linear: 2-1                       [32, 200]                 60,200\n│    └─ReLU: 2-2                         [32, 200]                 --\n│    └─Dropout: 2-3                      [32, 200]                 --\n│    └─Linear: 2-4                       [32, 100]                 20,100\n│    └─ReLU: 2-5                         [32, 100]                 --\n│    └─Dropout: 2-6                      [32, 100]                 --\n│    └─Linear: 2-7                       [32, 10]                  1,010\n│    └─ReLU: 2-8                         [32, 10]                  --\n│    └─Linear: 2-9                       [32, 1]                   11\n==========================================================================================\nTotal params: 81,321\nTrainable params: 81,321\nNon-trainable params: 0\nTotal mult-adds (M): 2.60\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 0.08\nParams size (MB): 0.33\nEstimated Total Size (MB): 0.44\n=========================================================================================="},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\noptimizer=torch.optim.Adam(params=mymodel.parameters(),lr=0.01, weight_decay=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:47:02.660859Z","iopub.execute_input":"2025-02-13T08:47:02.661171Z","iopub.status.idle":"2025-02-13T08:47:02.665632Z","shell.execute_reply.started":"2025-02-13T08:47:02.661143Z","shell.execute_reply":"2025-02-13T08:47:02.664837Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0.01):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.best_loss = float('inf')\n        self.counter = 0\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        return self.counter >= self.patience","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:47:09.002931Z","iopub.execute_input":"2025-02-13T08:47:09.003249Z","iopub.status.idle":"2025-02-13T08:47:09.008177Z","shell.execute_reply.started":"2025-02-13T08:47:09.003227Z","shell.execute_reply":"2025-02-13T08:47:09.007315Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    y_true = y_true.clone().cpu()\n    y_pred = y_pred.clone().cpu()\n\n    correct = torch.eq(y_true, y_pred).sum().item() \n    acc = (correct / len(y_pred)) * 100 \n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:41:30.123026Z","iopub.execute_input":"2025-02-13T07:41:30.123339Z","iopub.status.idle":"2025-02-13T07:41:30.127694Z","shell.execute_reply.started":"2025-02-13T07:41:30.123298Z","shell.execute_reply":"2025-02-13T07:41:30.126658Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def train_step(model,data_loader,loss_fn,optimizer:torch,accuracy_fn):\n  train_loss,train_acc=0,0\n  \n  for X,y in data_loader:\n      X, y = X.to(device), y.to(device)\n      \n      y_logits=model(X).squeeze()\n      y_pred_probs = torch.sigmoid(y_logits)\n      y_preds = torch.round(y_pred_probs)\n\n      loss=loss_fn(y_logits,y)\n      train_loss=train_loss+loss.item()\n      train_acc+=accuracy_fn(y_true=y.detach(),y_pred=y_preds.detach())\n      \n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n  \n  train_loss/=len(data_loader)\n  train_acc/=len(data_loader)\n  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n  return train_loss\n\ndef test_step(model,data_loader,loss_fn,accuracy_fn):\n  test_loss,test_acc=0,0\n\n  model.eval()\n\n  with torch.inference_mode():\n    for X,y in data_loader:\n        X, y = X.to(device), y.to(device) \n        \n        y_logits=model(X).squeeze()\n        y_pred_probs = torch.sigmoid(y_logits)\n        y_preds = torch.round(y_pred_probs)\n            \n        test_loss += loss_fn(y_logits, y).item()\n        test_acc += accuracy_fn(y_true=y.detach(),y_pred=y_preds.detach())\n    \n    test_loss /= len(data_loader)\n    test_acc /= len(data_loader)\n    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n    return test_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:09:33.774553Z","iopub.execute_input":"2025-02-13T08:09:33.774893Z","iopub.status.idle":"2025-02-13T08:09:33.782155Z","shell.execute_reply.started":"2025-02-13T08:09:33.774865Z","shell.execute_reply":"2025-02-13T08:09:33.781045Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"### BOW","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\nepochs=30\nearly_stopping = EarlyStopping()\nfor epoch in range(epochs):\n  print(\"epoch :\",epoch+1)\n  train=train_step(model=mymodel,\n             data_loader=train_dataloader_bow,\n             loss_fn=loss_fn,\n             optimizer=optimizer,\n             accuracy_fn=accuracy_fn)\n  \n  test=test_step(model=mymodel,\n            data_loader=test_dataloader_bow,\n            loss_fn=loss_fn,\n            accuracy_fn=accuracy_fn)\n\n  if early_stopping(test):\n      print(f\"Training halted at epoch {epoch + 1}\")\n      break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:12:24.886651Z","iopub.execute_input":"2025-02-13T08:12:24.886949Z","iopub.status.idle":"2025-02-13T08:13:42.903188Z","shell.execute_reply.started":"2025-02-13T08:12:24.886928Z","shell.execute_reply":"2025-02-13T08:13:42.902296Z"}},"outputs":[{"name":"stdout","text":"epoch : 1\nTrain loss: 0.19051 | Train accuracy: 93.46%\nTest loss: 0.52701 | Test accuracy: 85.23%\n\nepoch : 2\nTrain loss: 0.18629 | Train accuracy: 93.41%\nTest loss: 0.40154 | Test accuracy: 86.31%\n\nepoch : 3\nTrain loss: 0.12923 | Train accuracy: 95.60%\nTest loss: 0.57214 | Test accuracy: 85.52%\n\nepoch : 4\nTrain loss: 0.15076 | Train accuracy: 95.04%\nTest loss: 0.55297 | Test accuracy: 84.94%\n\nepoch : 5\nTrain loss: 0.12384 | Train accuracy: 95.99%\nTest loss: 0.58548 | Test accuracy: 85.21%\n\nepoch : 6\nTrain loss: 0.11620 | Train accuracy: 96.38%\nTest loss: 0.65738 | Test accuracy: 85.14%\n\nepoch : 7\nTrain loss: 0.10244 | Train accuracy: 96.68%\nTest loss: 0.66888 | Test accuracy: 84.98%\n\nTraining halted at epoch 7\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"### TFIDF","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\nepochs=30\nearly_stopping = EarlyStopping()\nfor epoch in range(epochs):\n  print(\"epoch :\",epoch+1)\n  train=train_step(model=mymodel,\n             data_loader=train_dataloader_tfidf,\n             loss_fn=loss_fn,\n             optimizer=optimizer,\n             accuracy_fn=accuracy_fn)\n  \n  test=test_step(model=mymodel,\n            data_loader=test_dataloader_tfidf,\n            loss_fn=loss_fn,\n            accuracy_fn=accuracy_fn)\n\n  if early_stopping(test):\n      print(f\"Training halted at epoch {epoch + 1}\")\n      break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:15:52.187777Z","iopub.execute_input":"2025-02-13T08:15:52.188093Z","iopub.status.idle":"2025-02-13T08:16:59.334512Z","shell.execute_reply.started":"2025-02-13T08:15:52.188066Z","shell.execute_reply":"2025-02-13T08:16:59.333785Z"}},"outputs":[{"name":"stdout","text":"epoch : 1\nTrain loss: 0.32935 | Train accuracy: 85.80%\nTest loss: 0.28462 | Test accuracy: 87.77%\n\nepoch : 2\nTrain loss: 0.26338 | Train accuracy: 89.18%\nTest loss: 0.27949 | Test accuracy: 88.20%\n\nepoch : 3\nTrain loss: 0.22324 | Train accuracy: 90.96%\nTest loss: 0.28201 | Test accuracy: 88.01%\n\nepoch : 4\nTrain loss: 0.16191 | Train accuracy: 93.82%\nTest loss: 0.31129 | Test accuracy: 87.57%\n\nepoch : 5\nTrain loss: 0.10627 | Train accuracy: 96.06%\nTest loss: 0.36732 | Test accuracy: 86.96%\n\nepoch : 6\nTrain loss: 0.07748 | Train accuracy: 97.19%\nTest loss: 0.40354 | Test accuracy: 86.48%\n\nTraining halted at epoch 6\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"### word2vec","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\nepochs=30\nearly_stopping = EarlyStopping()\nfor epoch in range(epochs):\n  print(\"epoch :\",epoch+1)\n  train=train_step(model=mymodel,\n             data_loader=train_dataloader_word2vec,\n             loss_fn=loss_fn,\n             optimizer=optimizer,\n             accuracy_fn=accuracy_fn)\n  \n  test=test_step(model=mymodel,\n            data_loader=test_dataloader_word2vec,\n            loss_fn=loss_fn,\n            accuracy_fn=accuracy_fn)\n\n  if early_stopping(test):\n      print(f\"Training halted at epoch {epoch + 1}\")\n      break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T08:47:19.305865Z","iopub.execute_input":"2025-02-13T08:47:19.306143Z","iopub.status.idle":"2025-02-13T08:47:44.337694Z","shell.execute_reply.started":"2025-02-13T08:47:19.306123Z","shell.execute_reply":"2025-02-13T08:47:44.336939Z"}},"outputs":[{"name":"stdout","text":"epoch : 1\nTrain loss: 0.44173 | Train accuracy: 80.37%\nTest loss: 0.36077 | Test accuracy: 83.72%\n\nepoch : 2\nTrain loss: 0.35838 | Train accuracy: 84.53%\nTest loss: 0.35319 | Test accuracy: 85.04%\n\nepoch : 3\nTrain loss: 0.35407 | Train accuracy: 84.86%\nTest loss: 0.33549 | Test accuracy: 85.24%\n\nepoch : 4\nTrain loss: 0.35059 | Train accuracy: 84.92%\nTest loss: 0.34099 | Test accuracy: 85.49%\n\nepoch : 5\nTrain loss: 0.34862 | Train accuracy: 84.94%\nTest loss: 0.33116 | Test accuracy: 85.74%\n\nepoch : 6\nTrain loss: 0.34211 | Train accuracy: 85.21%\nTest loss: 0.34015 | Test accuracy: 85.76%\n\nepoch : 7\nTrain loss: 0.34140 | Train accuracy: 85.14%\nTest loss: 0.35405 | Test accuracy: 84.99%\n\nepoch : 8\nTrain loss: 0.34178 | Train accuracy: 85.22%\nTest loss: 0.33331 | Test accuracy: 85.09%\n\nTraining halted at epoch 8\n","output_type":"stream"}],"execution_count":103},{"cell_type":"markdown","source":"### 7. LSTM","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 100\n\ndef text_to_embedding(text, word2vec_model, max_len=MAX_LEN):\n    words = text.split() \n    embeddings = []\n\n    for word in words:\n        if word in word2vec_model.wv:\n            embeddings.append(word2vec_model.wv[word])\n        else:\n            embeddings.append(np.zeros(300))\n\n    if len(embeddings) < max_len:\n        embeddings += [np.zeros(300)] * (max_len - len(embeddings))\n    else:\n        embeddings = embeddings[:max_len]\n\n    return np.array(embeddings)\n\nX_train_embeddings = np.array([text_to_embedding(text, word2vec_model) for text in X_train['cleaned_text']])\nX_test_embeddings = np.array([text_to_embedding(text, word2vec_model) for text in X_test['cleaned_text']])\n\nX_train_tensor = torch.tensor(X_train_embeddings, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_embeddings, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:32:18.709957Z","iopub.execute_input":"2025-02-13T19:32:18.710598Z","iopub.status.idle":"2025-02-13T19:32:42.076830Z","shell.execute_reply.started":"2025-02-13T19:32:18.710566Z","shell.execute_reply":"2025-02-13T19:32:42.075974Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import gc\n\ndel X_train_embeddings\ndel X_test_embeddings\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:34:25.961085Z","iopub.execute_input":"2025-02-13T19:34:25.961468Z","iopub.status.idle":"2025-02-13T19:34:26.401561Z","shell.execute_reply.started":"2025-02-13T19:34:25.961437Z","shell.execute_reply":"2025-02-13T19:34:26.400436Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2799"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:44:01.680445Z","iopub.execute_input":"2025-02-13T19:44:01.680788Z","iopub.status.idle":"2025-02-13T19:44:01.685856Z","shell.execute_reply.started":"2025-02-13T19:44:01.680766Z","shell.execute_reply":"2025-02-13T19:44:01.685100Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"X_train_tensor_word2vec = X_train_tensor.to(device) \nY_train_tensor_word2vec = torch.tensor(y_train, dtype=torch.float32).to(device)\n\ntrain_dataset = TensorDataset(X_train_tensor_word2vec, Y_train_tensor_word2vec)\n\ntrain_dataloader_word2vec = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nfor batch in train_dataloader_word2vec:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(train_dataloader_word2vec))\n\nX_test_tensor_word2vec = X_test_tensor.to(device)\nY_test_tensor_word2vec = torch.tensor(y_test, dtype=torch.float32).to(device) \n\ntest_dataset = TensorDataset(X_test_tensor_word2vec, Y_test_tensor_word2vec)\n\ntest_dataloader_word2vec = DataLoader(test_dataset, batch_size=32, shuffle=True)\n\nfor batch in test_dataloader_word2vec:\n    X_batch, Y_batch = batch\n    print(\"X_batch shape:\", X_batch.shape)\n    print(\"Y_batch shape:\", Y_batch.shape)\n    break  # Only print first batch\nprint(len(test_dataloader_word2vec))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:44:39.048162Z","iopub.execute_input":"2025-02-13T19:44:39.048633Z","iopub.status.idle":"2025-02-13T19:44:40.371940Z","shell.execute_reply.started":"2025-02-13T19:44:39.048584Z","shell.execute_reply":"2025-02-13T19:44:40.371125Z"}},"outputs":[{"name":"stdout","text":"X_batch shape: torch.Size([32, 100, 300])\nY_batch shape: torch.Size([32])\n1240\nX_batch shape: torch.Size([32, 100, 300])\nY_batch shape: torch.Size([32])\n310\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.lstm1=nn.LSTM(input_size=300,hidden_size=50,num_layers=3,batch_first=True,bidirectional=True)\n        self.fc = nn.Linear(50*2 ,1)\n\n    def forward(self,x):\n        lstm_out,_ = self.lstm1(x)\n        out = self.fc(lstm_out[:, -1, :])  # Last hidden state\n        return out\n\n\nmymodel = LSTM().to(device)\n        \n\nprint(\"Summary of the architecture (batch_size=32):\")\ntorchinfo.summary(mymodel, input_size=(32,100,300))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:16:22.798953Z","iopub.execute_input":"2025-02-13T20:16:22.799330Z","iopub.status.idle":"2025-02-13T20:16:22.826528Z","shell.execute_reply.started":"2025-02-13T20:16:22.799298Z","shell.execute_reply":"2025-02-13T20:16:22.825799Z"}},"outputs":[{"name":"stdout","text":"Summary of the architecture (batch_size=32):\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLSTM                                     [32, 1]                   --\n├─LSTM: 1-1                              [32, 100, 100]            262,400\n├─Linear: 1-2                            [32, 1]                   101\n==========================================================================================\nTotal params: 262,501\nTrainable params: 262,501\nNon-trainable params: 0\nTotal mult-adds (M): 839.68\n==========================================================================================\nInput size (MB): 3.84\nForward/backward pass size (MB): 2.56\nParams size (MB): 1.05\nEstimated Total Size (MB): 7.45\n=========================================================================================="},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\noptimizer=torch.optim.Adam(params=mymodel.parameters(),lr=0.01, weight_decay=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:16:29.708811Z","iopub.execute_input":"2025-02-13T20:16:29.709118Z","iopub.status.idle":"2025-02-13T20:16:29.713773Z","shell.execute_reply.started":"2025-02-13T20:16:29.709097Z","shell.execute_reply":"2025-02-13T20:16:29.712901Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    y_true = y_true.clone().cpu()\n    y_pred = y_pred.clone().cpu()\n\n    correct = torch.eq(y_true, y_pred).sum().item() \n    acc = (correct / len(y_pred)) * 100 \n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:07:58.380730Z","iopub.execute_input":"2025-02-13T20:07:58.381043Z","iopub.status.idle":"2025-02-13T20:07:58.385504Z","shell.execute_reply.started":"2025-02-13T20:07:58.381020Z","shell.execute_reply":"2025-02-13T20:07:58.384621Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"def train_step(model,data_loader,loss_fn,optimizer:torch,accuracy_fn):\n  model.train()\n  train_loss,train_acc=0,0\n  \n  for X,y in data_loader:\n      X, y = X.to(device), y.to(device)\n      \n      y_logits=model(X).squeeze()\n      y_pred_probs = torch.sigmoid(y_logits)\n      y_preds = torch.round(y_pred_probs)\n\n      loss=loss_fn(y_logits,y)\n      train_loss=train_loss+loss.item()\n      train_acc+=accuracy_fn(y_true=y.detach(),y_pred=y_preds.detach())\n      \n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n  \n  train_loss/=len(data_loader)\n  train_acc/=len(data_loader)\n  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n  return train_loss\n\ndef test_step(model,data_loader,loss_fn,accuracy_fn):\n  test_loss,test_acc=0,0\n\n  model.eval()\n\n  with torch.inference_mode():\n    for X,y in data_loader:\n        X, y = X.to(device), y.to(device) \n        \n        y_logits=model(X).squeeze()\n        y_pred_probs = torch.sigmoid(y_logits)\n        y_preds = torch.round(y_pred_probs)\n            \n        test_loss += loss_fn(y_logits, y).item()\n        test_acc += accuracy_fn(y_true=y.detach(),y_pred=y_preds.detach())\n    \n    test_loss /= len(data_loader)\n    test_acc /= len(data_loader)\n    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n    return test_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:08:01.466307Z","iopub.execute_input":"2025-02-13T20:08:01.466624Z","iopub.status.idle":"2025-02-13T20:08:01.474183Z","shell.execute_reply.started":"2025-02-13T20:08:01.466601Z","shell.execute_reply":"2025-02-13T20:08:01.473203Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"torch.manual_seed(42)\nepochs=30\nearly_stopping = EarlyStopping()\nfor epoch in range(epochs):\n  print(\"epoch :\",epoch+1)\n  train=train_step(model=mymodel,\n             data_loader=train_dataloader_word2vec,\n             loss_fn=loss_fn,\n             optimizer=optimizer,\n             accuracy_fn=accuracy_fn)\n  \n  test=test_step(model=mymodel,\n            data_loader=test_dataloader_word2vec,\n            loss_fn=loss_fn,\n            accuracy_fn=accuracy_fn)\n\n  if early_stopping(test):\n      print(f\"Training halted at epoch {epoch + 1}\")\n      break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:16:35.359455Z","iopub.execute_input":"2025-02-13T20:16:35.359789Z","iopub.status.idle":"2025-02-13T20:17:31.257437Z","shell.execute_reply.started":"2025-02-13T20:16:35.359763Z","shell.execute_reply":"2025-02-13T20:17:31.256366Z"}},"outputs":[{"name":"stdout","text":"epoch : 1\nTrain loss: 0.51698 | Train accuracy: 71.63%\nTest loss: 0.35527 | Test accuracy: 84.26%\n\nepoch : 2\nTrain loss: 0.34208 | Train accuracy: 85.22%\nTest loss: 0.33615 | Test accuracy: 85.32%\n\nepoch : 3\nTrain loss: 0.32967 | Train accuracy: 85.78%\nTest loss: 0.31849 | Test accuracy: 85.92%\n\nepoch : 4\nTrain loss: 0.32051 | Train accuracy: 86.33%\nTest loss: 0.32421 | Test accuracy: 86.10%\n\nepoch : 5\nTrain loss: 0.31505 | Train accuracy: 86.45%\nTest loss: 0.31434 | Test accuracy: 86.32%\n\nepoch : 6\nTrain loss: 0.31168 | Train accuracy: 86.68%\nTest loss: 0.31933 | Test accuracy: 86.03%\n\nepoch : 7\nTrain loss: 0.30886 | Train accuracy: 86.66%\nTest loss: 0.31661 | Test accuracy: 86.09%\n\nepoch : 8\nTrain loss: 0.30670 | Train accuracy: 86.83%\nTest loss: 0.31097 | Test accuracy: 86.71%\n\nTraining halted at epoch 8\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tabulate import tabulate\n\ndata = {\n    \"Model\": [\"MultinomialNB\", \"GaussianNB\", \"Random Forest\", \"XGBoost\", \"CatBoost\", \"LightGBM\", \"ANN\", \"LSTM\"],\n    \"BoW\": [0.8437, 0.7137, 0.8432, 0.8511, 0.8710, 0.8561, 0.8498,None ],\n    \"TF-IDF\": [0.8531, 0.7770, 0.8428, 0.8541, 0.8662, 0.8566, 0.8648, None],  \n    \"Word2Vec\": [None, 0.7544, 0.8255, 0.8436, 0.8574, 0.8455, 0.8509, 0.8671] \n}\n\ndf = pd.DataFrame(data)\n\nprint(tabulate(df, headers=\"keys\", tablefmt=\"grid\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T00:58:27.384003Z","iopub.execute_input":"2025-02-14T00:58:27.384303Z","iopub.status.idle":"2025-02-14T00:58:27.391763Z","shell.execute_reply.started":"2025-02-14T00:58:27.384281Z","shell.execute_reply":"2025-02-14T00:58:27.390916Z"}},"outputs":[{"name":"stdout","text":"+----+---------------+----------+----------+------------+\n|    | Model         |      BoW |   TF-IDF |   Word2Vec |\n+====+===============+==========+==========+============+\n|  0 | MultinomialNB |   0.8437 |   0.8531 |   nan      |\n+----+---------------+----------+----------+------------+\n|  1 | GaussianNB    |   0.7137 |   0.777  |     0.7544 |\n+----+---------------+----------+----------+------------+\n|  2 | Random Forest |   0.8432 |   0.8428 |     0.8255 |\n+----+---------------+----------+----------+------------+\n|  3 | XGBoost       |   0.8511 |   0.8541 |     0.8436 |\n+----+---------------+----------+----------+------------+\n|  4 | CatBoost      |   0.871  |   0.8662 |     0.8574 |\n+----+---------------+----------+----------+------------+\n|  5 | LightGBM      |   0.8561 |   0.8566 |     0.8455 |\n+----+---------------+----------+----------+------------+\n|  6 | ANN           |   0.8498 |   0.8648 |     0.8509 |\n+----+---------------+----------+----------+------------+\n|  7 | LSTM          | nan      | nan      |     0.8671 |\n+----+---------------+----------+----------+------------+\n","output_type":"stream"}],"execution_count":11}]}